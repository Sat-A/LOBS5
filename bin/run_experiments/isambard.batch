#!/bin/bash
#SBATCH --job-name=lobs5_tok24
#SBATCH --output=logs_lobs5_tok24/lobs5_%j.out
#SBATCH --error=logs_lobs5_tok24/lobs5_%j.err
#SBATCH --nodes=1
# One task per node by default (override with CLI if needed)
#SBATCH --ntasks-per-node=1
# Request 4 GPUs per node by default (override with CLI if needed)
# Use GRES syntax for compatibility on this site
#SBATCH --gres=gpu:4
#SBATCH --mem=0
#SBATCH --time=00:09:59


# Source conda
source ~/miniforge3/etc/profile.d/conda.sh

# Activate environment
conda activate lobs5

# Load CUDA module
module load cuda/12.6

# Set LD_LIBRARY_PATH for JAX CUDA libraries (complete list from working environment)
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cuda_nvrtc/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cuda_runtime/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cusparse/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cuda_cupti/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cufft/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/nvjitlink/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cusolver/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/nccl/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/nvshmem/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cublas/lib:$CONDA_PREFIX/lib/python3.11/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH

cd /lus/lfs1aip2/home/s5e/kangli.s5e/AlphaTrade/LOBS5/
mkdir -p logs_lobs5_tok24

find /lus/lfs1aip2/home/s5e/kangli.s5e/AlphaTrade/LOBS5 -type d -name '__pycache__' -exec rm -rf {} +


# clear JAX compile cache
export XLA_FLAGS="--xla_force_host_platform_device_count=4"
rm -rf ~/.cache/jax_cache
rm -rf /tmp/__pycache__/jax*
# clear Python cache
find . -type d -name '__pycache__' -exec rm -rf {} +
find . -name '*.pyc' -delete


bash /lus/lfs1aip2/home/s5e/kangli.s5e/AlphaTrade/LOBS5/bin/run_experiments/run_lobster_padded_large.sh